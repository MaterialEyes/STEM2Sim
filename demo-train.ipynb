{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import bisect\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from heapq import heappop, heappush, heapify\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.network import SupConResNet_v\n",
    "from src.utils.loss import SupConLoss\n",
    "from src.utils.stem_dataset import STEMDataset, ToTensor, collate_fn, RandomCrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters you may need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"<change_the_path>/atomagined/key.csv\" # path to the annotation file\n",
    "root_dir = \"<change_the_path>/atomagined/general/png/\" # dir of the STEM images\n",
    "csv_file = \"/home/weixin/Documents/data/MaterialEyes/atomagined/key.csv\"\n",
    "root_dir = \"/home/weixin/Documents/data/MaterialEyes/atomagined/general/png/\"\n",
    "batch_size = 20 # parameter for model training, depends on the GPU MEMORY\n",
    "image_size = 200 # parameter for input enhancement for training (crop_size)\n",
    "device=\"cuda:0\" # parameter for gpu id selectoin (in case of more than one gpu)\n",
    "max_epoch = 1000 # the maximum epochs for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset. Time elapsed 131.17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5998, 299)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "dataset = STEMDataset(csv_file, root_dir, transform=transforms.Compose([RandomCrop(image_size), ToTensor()]))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "print(\"loading dataset. Time elapsed %.2f\"%(time.time()-start))\n",
    "len(dataset), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "net parameters:\n",
    "name: may select different resnet as the backbone [resnet18, resnet34, resnet50, resnet101]\n",
    "head: the projection head for the contrastive learning [mlp, linear, none]\n",
    "cls: the classification task [icsd, symtable]\n",
    "feat_dim: the dimensionality of the metric space for contrastive loss \n",
    "computing, only works if the head is not none\n",
    "\"\"\"\n",
    "\n",
    "net = SupConResNet_v(name='resnet18', head=\"mlp\", cls=\"icsd\", feat_dim=128) # mlp head + icsd\n",
    "\n",
    "\n",
    "\n",
    "# in case you have pretrained model for model initializatoin \n",
    "#net.load_state_dict(torch.load(\"resnet18_cls_none_sim_none_epoch181.pt\", map_location=\"cpu\"), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 15/299 [00:21<06:52,  1.45s/batch, cls_loss=9.06, loss=14.2, sim_loss=5.16]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1410409/3467442010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# save model for every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./resnet18_epoch%.3d.pt\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3) # optimizer, [Adam, SGD]\n",
    "criterion_cls = torch.nn.CrossEntropyLoss() # cross entropy loss for classification task\n",
    "criterion_sim = SupConLoss(temperature=0.1) # loss for contrastive learning\n",
    "net.train()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "            \"\"\"\n",
    "            data[\"imgs\"]: batch of image data\n",
    "            data[\"labels\"]: [ref_ids, icsd_ids, symtable_ids]\n",
    "            \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            imgs, labels = data[\"imgs\"].to(device), data[\"labels\"][1].to(torch.int64).to(device)\n",
    "            pred, cls_pred = net(imgs)\n",
    "            f1, f2 = torch.split(pred, [batch_size, batch_size], dim=0)\n",
    "            pred = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "            cls_loss = criterion_cls(cls_pred, labels)\n",
    "            sim_loss = criterion_sim(pred)\n",
    "            loss = cls_loss + sim_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(loss=float(loss), cls_loss=float(cls_loss), sim_loss=float(sim_loss))\n",
    "    # save model for every epoch\n",
    "    torch.save(net.state_dict(), \"./resnet18_epoch%.3d.pt\"%(epoch))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (STEM2SIM)",
   "language": "python",
   "name": "stem2sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
